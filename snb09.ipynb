{"cells":[{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-06-11T00:36:30.520828Z","iopub.status.busy":"2023-06-11T00:36:30.520462Z","iopub.status.idle":"2023-06-11T00:36:52.286091Z","shell.execute_reply":"2023-06-11T00:36:52.284925Z","shell.execute_reply.started":"2023-06-11T00:36:30.520797Z"},"executionInfo":{"elapsed":19359,"status":"ok","timestamp":1685803538963,"user":{"displayName":"Ameck Dosseh","userId":"09603352587859208137"},"user_tz":-60},"id":"rp6SHN_OuD_Q","outputId":"a9f81267-9c1e-4540-8988-b997439ce830","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["# Slidin' Videos: Use high-precision text tracking and semantic segmentation for chapters generation\n","\n","#### Please register for the Slidin' Videos challenge to get download URLs used in this notebook \n","\n","## 1. Deeplab finetuning\n","#### DeepLabV3 model is a pretrained model for semantic segmentation of images. We will finetune it on Slidin' Videos dataset of slide titles\n","\n","# !git clone https://github.com/msminhas93/DeepLabv3FineTuning.git\n","!pip install -q torch torchvision pandas scikit-learn\n","!pip install -q opencv-python-headless Shapely Pillow easyocr\n"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-06-11T00:36:52.290175Z","iopub.status.busy":"2023-06-11T00:36:52.289498Z","iopub.status.idle":"2023-06-11T00:36:52.294969Z","shell.execute_reply":"2023-06-11T00:36:52.293732Z","shell.execute_reply.started":"2023-06-11T00:36:52.290119Z"},"trusted":true},"outputs":[],"source":["# !pip install -q Pillow==6.2.2"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-06-11T00:36:52.296751Z","iopub.status.busy":"2023-06-11T00:36:52.296240Z","iopub.status.idle":"2023-06-11T00:36:52.309861Z","shell.execute_reply":"2023-06-11T00:36:52.308938Z","shell.execute_reply.started":"2023-06-11T00:36:52.296713Z"},"trusted":true},"outputs":[],"source":["# from IPython.core.display import HTML\n","# HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-06-11T00:36:52.313142Z","iopub.status.busy":"2023-06-11T00:36:52.312645Z","iopub.status.idle":"2023-06-11T00:37:02.877351Z","shell.execute_reply":"2023-06-11T00:37:02.876065Z","shell.execute_reply.started":"2023-06-11T00:36:52.313100Z"},"trusted":true},"outputs":[],"source":["#comment or skip if in colab\n","!cp /kaggle/input/notebookb7b076d71e/* /kaggle/working/"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-06-11T00:37:02.880001Z","iopub.status.busy":"2023-06-11T00:37:02.879626Z","iopub.status.idle":"2023-06-11T00:37:03.870054Z","shell.execute_reply":"2023-06-11T00:37:03.868927Z","shell.execute_reply.started":"2023-06-11T00:37:02.879962Z"},"executionInfo":{"elapsed":410,"status":"ok","timestamp":1685803609379,"user":{"displayName":"Ameck Dosseh","userId":"09603352587859208137"},"user_tz":-60},"id":"0iFb5gpzuZXD","outputId":"b0cfb56a-530d-4959-ee8d-0a1580158ed6","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["DeepLabv3FineTuning\t\t     Train.csv\n","SampleSubmission.csv\t\t     Train.zip\n","SlidinVideos_StarterNotebook.ipynb   __notebook__.ipynb\n","Submission_fcn_resnet50.csv\t     __notebook_source__.ipynb\n","Submission_fcn_resnet50_epchs50.csv  __output__.json\n","Test\t\t\t\t     __results__.html\n","Test.zip\t\t\t     custom.css\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-06-11T00:37:03.873588Z","iopub.status.busy":"2023-06-11T00:37:03.873271Z","iopub.status.idle":"2023-06-11T00:37:03.880561Z","shell.execute_reply":"2023-06-11T00:37:03.879675Z","shell.execute_reply.started":"2023-06-11T00:37:03.873558Z"},"executionInfo":{"elapsed":39050,"status":"ok","timestamp":1685804043920,"user":{"displayName":"Ameck Dosseh","userId":"09603352587859208137"},"user_tz":-60},"id":"1jkEZp1euL8c","trusted":true},"outputs":[],"source":["#### Download title masks collection and unzip it to the cloned repository. \n","\n","# !unzip -q Train.zip -d DeepLabv3FineTuning/"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-06-11T00:37:03.882344Z","iopub.status.busy":"2023-06-11T00:37:03.882007Z","iopub.status.idle":"2023-06-11T00:37:04.883274Z","shell.execute_reply":"2023-06-11T00:37:04.881997Z","shell.execute_reply.started":"2023-06-11T00:37:03.882309Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Analysis.ipynb\tREADME.md\t\t       datahandler.py\t segdataset.py\n","CFExp\t\tSegmentationDatasetDemo.ipynb  environment.yml\t trainer.py\n","CrackForest\tTests\t\t\t       main.py\n","DemoExp\t\tTrain\t\t\t       model.py\n","LICENSE.md\t__pycache__\t\t       requirements.txt\n"]}],"source":["!ls DeepLabv3FineTuning"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-06-11T00:37:04.887383Z","iopub.status.busy":"2023-06-11T00:37:04.886975Z","iopub.status.idle":"2023-06-11T00:37:04.892717Z","shell.execute_reply":"2023-06-11T00:37:04.891172Z","shell.execute_reply.started":"2023-06-11T00:37:04.887353Z"},"trusted":true},"outputs":[],"source":["# !mkdir DeepLabv3FineTuning/Train"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-06-11T00:37:04.894656Z","iopub.status.busy":"2023-06-11T00:37:04.893834Z","iopub.status.idle":"2023-06-11T00:37:05.337691Z","shell.execute_reply":"2023-06-11T00:37:05.336656Z","shell.execute_reply.started":"2023-06-11T00:37:04.894623Z"},"trusted":true},"outputs":[],"source":["# !mv DeepLabv3FineTuning/Images DeepLabv3FineTuning/Train\n","# !mv DeepLabv3FineTuning/Masks DeepLabv3FineTuning/Train"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-06-11T00:37:05.343831Z","iopub.status.busy":"2023-06-11T00:37:05.343096Z","iopub.status.idle":"2023-06-11T00:37:05.650308Z","shell.execute_reply":"2023-06-11T00:37:05.649409Z","shell.execute_reply.started":"2023-06-11T00:37:05.343795Z"},"id":"TbZX1CnauSww","outputId":"ab8960ff-2e89-4432-bc07-a9f42e1ba291","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working/DeepLabv3FineTuning\n"]}],"source":["#### Training DeepLab model: our goal is to maximize test_f1_score\n","#### You may want to play with number of epochs, learning rate and loss function to get better results\n","\n","%cd DeepLabv3FineTuning\n","from pathlib import Path\n","\n","#from segmentation_models_pytorch.losses.jaccard  import JaccardLoss\n","#from segmentation_models_pytorch.losses.constants import BINARY_MODE\n","#criterion = JaccardLoss(mode=BINARY_MODE)\n","\n","import torch\n","from sklearn.metrics import f1_score, roc_auc_score\n","from torch.utils import data\n","\n","import datahandler\n","from model import createDeepLabv3\n","from trainer import train_model"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-06-11T00:37:05.652039Z","iopub.status.busy":"2023-06-11T00:37:05.651660Z","iopub.status.idle":"2023-06-11T00:37:05.658666Z","shell.execute_reply":"2023-06-11T00:37:05.657798Z","shell.execute_reply.started":"2023-06-11T00:37:05.652006Z"},"trusted":true},"outputs":[],"source":["\"\"\" FCN Model download and change the head for your prediction\"\"\"\n","from torchvision.models.segmentation.fcn import FCNHead\n","from torchvision.models.segmentation import FCN_ResNet101_Weights\n","from torchvision import models\n","\n","\n","def createFCN(outputchannels=1):\n","    \"\"\"FCN class with custom head\n","\n","    Args:\n","        outputchannels (int, optional): The number of output channels\n","        in your dataset masks. Defaults to 1.\n","\n","    Returns:\n","        model: Returns the DeepLabv3 model with the ResNet50 backbone.\n","    \"\"\"\n","    model = models.segmentation.fcn_resnet101(pretrained=True,\n","                                                    progress=True,\n","                                             weights=FCN_ResNet101_Weights.DEFAULT\n","                                             )\n","    model.classifier = FCNHead(2048, outputchannels)\n","    # Set the model in training mode\n","    model.train()\n","    return model"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-06-11T00:37:05.660548Z","iopub.status.busy":"2023-06-11T00:37:05.659991Z","iopub.status.idle":"2023-06-11T00:37:07.904438Z","shell.execute_reply":"2023-06-11T00:37:07.903369Z","shell.execute_reply.started":"2023-06-11T00:37:05.660515Z"},"id":"IE1qQYjOwGg3","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/fcn_resnet101_coco-7ecb50ca.pth\" to /root/.cache/torch/hub/checkpoints/fcn_resnet101_coco-7ecb50ca.pth\n","100%|██████████| 208M/208M [00:00<00:00, 246MB/s]  \n"]},{"data":{"text/plain":["FCN(\n","  (backbone): IntermediateLayerGetter(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (4): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (5): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (6): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (7): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (8): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (9): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (10): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (11): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (12): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (13): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (14): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (15): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (16): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (17): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (18): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (19): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (20): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (21): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (22): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","  )\n","  (classifier): FCNHead(\n","    (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Dropout(p=0.1, inplace=False)\n","    (4): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n","  )\n","  (aux_classifier): FCNHead(\n","    (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Dropout(p=0.1, inplace=False)\n","    (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n","  )\n",")"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["# Create the deeplabv3 resnet101 model which is pretrained on a subset\n","# of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.\n","model = createFCN()\n","model.train()"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2023-06-11T00:37:07.906797Z","iopub.status.busy":"2023-06-11T00:37:07.905891Z","iopub.status.idle":"2023-06-11T00:37:07.994950Z","shell.execute_reply":"2023-06-11T00:37:07.993314Z","shell.execute_reply.started":"2023-06-11T00:37:07.906762Z"},"trusted":true},"outputs":[],"source":["from pathlib import Path\n","\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","\n","from segdataset import SegmentationDataset\n","import multiprocessing\n","pool = multiprocessing.Pool()\n","\n","\n","def get_dataloader_sep_folder(data_dir: str,\n","                              image_folder: str = 'Image',\n","                              mask_folder: str = 'Mask',\n","                              batch_size: int = 4):\n","    \"\"\" Create Train and Test dataloaders from two\n","        separate Train and Test folders.\n","        The directory structure should be as follows.\n","        data_dir\n","        --Train\n","        ------Image\n","        ---------Image1\n","        ---------ImageN\n","        ------Mask\n","        ---------Mask1\n","        ---------MaskN\n","        --Test\n","        ------Image\n","        ---------Image1\n","        ---------ImageM\n","        ------Mask\n","        ---------Mask1\n","        ---------MaskM\n","\n","    Args:\n","        data_dir (str): The data directory or root.\n","        image_folder (str, optional): Image folder name. Defaults to 'Image'.\n","        mask_folder (str, optional): Mask folder name. Defaults to 'Mask'.\n","        batch_size (int, optional): Batch size of the dataloader. Defaults to 4.\n","\n","    Returns:\n","        dataloaders: Returns dataloaders dictionary containing the\n","        Train and Test dataloaders.\n","    \"\"\"\n","    data_transforms = transforms.Compose([transforms.ToTensor()])\n","\n","    image_datasets = {\n","        x: SegmentationDataset(root=Path(data_dir) / x,\n","                               transforms=data_transforms,\n","                               image_folder=image_folder,\n","                               mask_folder=mask_folder)\n","        for x in ['Train', 'Test']\n","    }\n","    dataloaders = {\n","        x: DataLoader(image_datasets[x],\n","                      batch_size=batch_size,\n","                      shuffle=True,\n","                      num_workers=pool._processes)\n","        for x in ['Train', 'Test']\n","    }\n","    return dataloaders\n","\n","\n","def get_dataloader_single_folder(data_dir: str,\n","                                 image_folder: str = 'Images',\n","                                 mask_folder: str = 'Masks',\n","                                 fraction: float = 0.2,\n","                                 batch_size: int = 4):\n","    \"\"\"Create train and test dataloader from a single directory containing\n","    the image and mask folders.\n","\n","    Args:\n","        data_dir (str): Data directory path or root\n","        image_folder (str, optional): Image folder name. Defaults to 'Images'.\n","        mask_folder (str, optional): Mask folder name. Defaults to 'Masks'.\n","        fraction (float, optional): Fraction of Test set. Defaults to 0.2.\n","        batch_size (int, optional): Dataloader batch size. Defaults to 4.\n","\n","    Returns:\n","        dataloaders: Returns dataloaders dictionary containing the\n","        Train and Test dataloaders.\n","    \"\"\"\n","    data_transforms = transforms.Compose([transforms.ToTensor()])\n","\n","    image_datasets = {\n","        x: SegmentationDataset(data_dir,\n","                               image_folder=image_folder,\n","                               mask_folder=mask_folder,\n","                               seed=100,\n","                               fraction=fraction,\n","                               subset=x,\n","                               transforms=data_transforms)\n","        for x in ['Train', 'Test']\n","    }\n","    dataloaders = {\n","        x: DataLoader(image_datasets[x],\n","                      batch_size=batch_size,\n","                      shuffle=True,\n","                      num_workers=pool._processes)\n","        for x in ['Train', 'Test']\n","    }\n","    return dataloaders"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-06-11T00:37:07.999738Z","iopub.status.busy":"2023-06-11T00:37:07.999408Z","iopub.status.idle":"2023-06-11T00:37:08.005209Z","shell.execute_reply":"2023-06-11T00:37:08.004315Z","shell.execute_reply.started":"2023-06-11T00:37:07.999704Z"},"trusted":true},"outputs":[],"source":["datahandler.get_dataloader_single_folder = get_dataloader_single_folder"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-11T00:37:08.007924Z","iopub.status.busy":"2023-06-11T00:37:08.007146Z"},"id":"36mJmWfrwHiu","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","----------\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 427/427 [12:15<00:00,  1.72s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss: 0.0155\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 107/107 [01:47<00:00,  1.01s/it]"]},{"name":"stdout","output_type":"stream","text":["Test Loss: 0.0097\n","{'epoch': 1, 'Train_loss': 0.01546681672334671, 'Test_loss': 0.009711787104606628, 'Train_f1_score': 0.48038826291974335, 'Train_auroc': 0.9557239986366792, 'Test_f1_score': 0.6213690589186102, 'Test_auroc': 0.9750829562369402}\n","Epoch 2/50\n","----------\n"]},{"name":"stderr","output_type":"stream","text":["\n","100%|██████████| 427/427 [12:08<00:00,  1.71s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss: 0.0131\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 107/107 [01:45<00:00,  1.01it/s]"]},{"name":"stdout","output_type":"stream","text":["Test Loss: 0.0132\n","{'epoch': 2, 'Train_loss': 0.013147267512977123, 'Test_loss': 0.013223299756646156, 'Train_f1_score': 0.6371784069544981, 'Train_auroc': 0.983394182124267, 'Test_f1_score': 0.7146741891498855, 'Test_auroc': 0.9776998853046144}\n","Epoch 3/50\n","----------\n"]},{"name":"stderr","output_type":"stream","text":["\n"," 73%|███████▎  | 311/427 [08:54<03:16,  1.70s/it]"]}],"source":["data_directory = Path(\"Train\")\n","# Create the experiment directory if not present\n","exp_directory = Path(\"DemoExp\")\n","if not exp_directory.exists():\n","    exp_directory.mkdir()\n","\n","epochs = 50\n","\n","# Specify the evaluation metrics\n","metrics = {'f1_score': f1_score, 'auroc': roc_auc_score}\n","\n","# Create the dataloader\n","dataloaders = datahandler.get_dataloader_single_folder(\n","    data_directory, fraction=0.2, image_folder=\"Images\", \n","    mask_folder=\"Masks\", batch_size=4)\n","\n","\n","\n","# Specify the loss function\n","criterion = torch.nn.MSELoss(reduction='mean')\n","\n","# Specify the optimizer with a lower learning rate\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","_ = train_model(model, \n","                criterion,\n","                dataloaders,\n","                optimizer,\n","                bpath=exp_directory,\n","                metrics=metrics,\n","                num_epochs=epochs)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E0_cEwS_wP7P","trusted":true},"outputs":[],"source":["\n","# Save the trained model\n","torch.save(model, exp_directory / 'weights.pt')\n","\n","# Terminate\n","exit()\n","%cd ../\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sba8VNgMwQ3f","trusted":true},"outputs":[],"source":["## 2. Making the submission\n","#### Unpack the testset\n","# !unzip -q Test.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# !mkdir Test\n","# !mv Images/ Test/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xGRe2fN0wVFN","trusted":true},"outputs":[],"source":["#### Load finetuned deeplab model and define helper functions\n","\n","import glob\n","import os\n","import json\n","import cv2    \n","import torch\n","import numpy as np\n","import pandas as pd\n","\n","from torchvision import transforms  \n","from PIL import Image\n","\n","deeplab_width = 768\n","deeplab_height = 432\n","deeplab = torch.load('DeepLabv3FineTuning/DemoExp/weights.pt')\n","deeplab.eval()\n","     \n","\n","def boxify(out, boxes):\n","    return [ torch.mean(out[b[0]:b[1], b[2]:b[3]]).item()  for b in boxes ]      \n","\n","def titlesegment(image, boxes):\n","    # Resize the frame to the training input size\n","    inputs = transforms.ToTensor()(Image.fromarray(image, mode=\"RGB\"))\n","    inputs = inputs.reshape(1, *inputs.shape).to('cuda')\n","    \n","    with torch.set_grad_enabled(False):\n","        outputs = deeplab(inputs)\n","        out = outputs['out'][0][0]\n","        box_scores = boxify(out, boxes)\n","        return out, np.array(box_scores)\n","    \n","def occupation(boxes):\n","    area = lambda b: (b[1]-b[0]) * (b[3]-b[2])\n","    y1, y2 = min([b[0] for b in boxes ]), max([b[1] for b in boxes ])\n","    x1, x2 = min([b[2] for b in boxes ]), max([b[3] for b in boxes ])\n","    return 1.0 * sum([ area(b) for b in boxes ]) / area([y1, y2, x1, x2])\n","\n","# Locates a paragraph of text with the highest probability \n","# to be a slide title \n","def pickonetitle(boxes, scores):\n","    if len(boxes) == 0:\n","        return []\n","        \n","    best_idx = np.argmax(scores)\n","    best = boxes[best_idx]\n","\n","    candidates = { i for i, box in enumerate(boxes) \n","        if abs(box['fontsize']-best['fontsize']) <= best['fontsize'] * 0.25 \n","            and scores[best_idx] - scores[i] < 0.6 }\n","    \n","    while occupation([ boxes[i]['bbox'] for i in candidates ]) < 0.75:\n","        combinations = [ candidates - {j} for j in candidates if j != best_idx ]\n","        candidates = max(combinations, \n","            key=lambda comb: occupation([ boxes[j]['bbox'] for j in comb ]))\n","            \n","    title_boxes = [ boxes[i] for i in candidates ]\n","    return title_boxes    \n","\n","#### Now, we're going to use EasyOCR package to \"read\" the titles. Modern OCR solutions may still produce a handful of errors, which is why you're encouraged to apply a language model or alternative OCR model to fix possible misspelings. \n","\n","from shapely.geometry import Polygon, LineString\n","\n","import easyocr\n","reader = easyocr.Reader(['en']) \n","\n","def sameline(a, b):\n","    return ((min(a['bbox'][1], b['bbox'][1]) - max(a['bbox'][0], b['bbox'][0]))\n","            / min(a['height'], b['height'])) >= 0.8\n","            \n","def isbelow(a, b):\n","    return not sameline(a, b) and a['bbox'][0] > b['bbox'][0]  \n","    \n","def isright(a, b):\n","    return sameline(a, b) and a['bbox'][2] > b['bbox'][2]  \n","\n","def sort_boxes(boxes):              \n","    boxes_ = []\n","    for b in boxes:\n","        i = 0\n","        while i < len(boxes_) and (isbelow(b, boxes_[i]) or isright(b, boxes_[i])):\n","            i += 1\n","        boxes_.insert(i, b)\n","    return boxes_\n","\n","def _norm_bbox(bbox):\n","    return  [ int(max(0, min([ p[1] for p in bbox ]))), \n","              int(max([ p[1] for p in bbox ])), \n","              int(max(0, min([ p[0] for p in bbox ]))), \n","              int(max([ p[0] for p in bbox ])) ]\n","\n","def process_ocr(ocr_results):\n","    items = []\n","    for bbox, text, conf in ocr_results:\n","        if text == '' or conf <= 0:\n","            continue  \n","        if not isinstance(bbox, list):\n","            bbox = bbox.tolist()\n","        item = {}\n","        item['width'] = LineString(bbox[0:2]).length\n","        item['height'] = LineString(bbox[1:3]).length\n","        item['area'] = item['width'] * item['height']\n","        item['fontsize'] = 1.0 * item['width'] / len(text)\n","        item['bbox'] = _norm_bbox(bbox)            \n","        item['text'] = text\n","        item['conf'] = float(conf)\n","        items.append(item)\n","    return items     \n","\n","def read_text(img):\n","    return process_ocr(reader.readtext(img))\n","\n","### Data exploration\n","#### First, we will pick some random test slide and will extract any instance of text on it\n","\n","from IPython.display import display, JSON, Image as IImage\n","\n","def draw_boxes(frame, boxes):\n","    for box in boxes:\n","        frame = cv2.rectangle(frame, (box[2], box[0]), (box[3], box[1]), (36,255,12), 2)\n","    return frame"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!ls Test/Images/*33.jpg"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!ls Test/Images/*.jpg | wc -l"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# !ls Test/Images/*.jpg | head -n 5"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import re\n","''.join(re.findall(r'\\d+', \"Id_0khgx7z8tk.jpg\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Px7j8fmXwirJ","trusted":true},"outputs":[],"source":["# Load some test image and read the text on it\n","slide_ = cv2.imread('Test/Images/Id_76dbm25833.jpg')\n","\n","textboxes_ = read_text(slide_)\n","\n","textdata_ = pd.DataFrame(list(textboxes_))\n","del textdata_['conf']\n","             \n","slide_debug_ = draw_boxes(slide_, [ box['bbox'] for box in textboxes_ ])\n","\n","display(f\"Test slide #33\", \n","    Image.fromarray(slide_debug_).resize((640,360)), textdata_.head(5))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["slide_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LtmwXdD6wn80","trusted":true},"outputs":[],"source":["#### Now, we will apply finetuned DeepLab model and \"score\" each textbox as to whether it might be a title or not\n","\n","out, scores = titlesegment(slide_, [ box['bbox'] for box in textboxes_ ])\n","out_mask = (np.abs(out.cpu().numpy())*255).astype(np.uint8)\n","\n","textdata_['score'] = scores\n","\n","display(f\"Test slide #33 (segmentation output)\", Image.fromarray(out_mask).resize((640,360)), textdata_.head(5))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# [''.join(re.findall(r'\\d+', x)) for x in os.listdir('Test/Images')]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IyHd80jFwrWi","trusted":true},"outputs":[],"source":["#### Iterate this method on all test images\n","from tqdm import tqdm\n","\n","images = sorted(glob.glob('Test/Images/*.jpg'))\n","result = []\n","\n","for path in tqdm(images):\n","    image = cv2.imread(path)\n","    textboxes = read_text(image)\n","\n","    out, scores = titlesegment(image, [ box['bbox'] for box in textboxes ])\n","    titleboxes = pickonetitle(textboxes, scores)\n","    \n","    # Sort text boxes as you would read it in English: from top to bottom\n","    # and from left to right\n","    titleboxes = sort_boxes(titleboxes)\n","    title = ' '.join(box['text'] for box in titleboxes)    \n","    \n","    image_id = path.split(\"/\")[-1] #int(''.join(re.findall(r'\\d+', path.split('.')[0].split('/')[-1])))\n","    result.append([image_id, title])\n","\n","\n","#### Convert the result to a dataframe and save it\n","\n","df = pd.DataFrame.from_records(result, columns=['ID','Title'])\n","df\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":626,"status":"ok","timestamp":1685803454703,"user":{"displayName":"Ameck Dosseh","userId":"09603352587859208137"},"user_tz":-60},"id":"GedXAwZ0tog7","trusted":true},"outputs":[],"source":["df.to_csv('Submission_fcn_resnet101_epchs50.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
