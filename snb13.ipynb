{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "576f75d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T23:12:49.628508Z",
     "iopub.status.busy": "2023-06-09T23:12:49.628040Z",
     "iopub.status.idle": "2023-06-09T23:13:12.727238Z",
     "shell.execute_reply": "2023-06-09T23:13:12.726077Z"
    },
    "executionInfo": {
     "elapsed": 19359,
     "status": "ok",
     "timestamp": 1685803538963,
     "user": {
      "displayName": "Ameck Dosseh",
      "userId": "09603352587859208137"
     },
     "user_tz": -60
    },
    "id": "rp6SHN_OuD_Q",
    "outputId": "a9f81267-9c1e-4540-8988-b997439ce830",
    "papermill": {
     "duration": 23.113319,
     "end_time": "2023-06-09T23:13:12.729958",
     "exception": false,
     "start_time": "2023-06-09T23:12:49.616639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Slidin' Videos: Use high-precision text tracking and semantic segmentation for chapters generation\n",
    "\n",
    "#### Please register for the Slidin' Videos challenge to get download URLs used in this notebook \n",
    "\n",
    "## 1. Deeplab finetuning\n",
    "#### DeepLabV3 model is a pretrained model for semantic segmentation of images. We will finetune it on Slidin' Videos dataset of slide titles\n",
    "\n",
    "# !git clone https://github.com/msminhas93/DeepLabv3FineTuning.git\n",
    "!pip install -q torch torchvision pandas scikit-learn\n",
    "!pip install -q opencv-python-headless Shapely Pillow easyocr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2552509",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T23:13:12.750174Z",
     "iopub.status.busy": "2023-06-09T23:13:12.749858Z",
     "iopub.status.idle": "2023-06-09T23:13:12.754505Z",
     "shell.execute_reply": "2023-06-09T23:13:12.753530Z"
    },
    "papermill": {
     "duration": 0.017167,
     "end_time": "2023-06-09T23:13:12.756534",
     "exception": false,
     "start_time": "2023-06-09T23:13:12.739367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -q Pillow==6.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc6ea7da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T23:13:12.776277Z",
     "iopub.status.busy": "2023-06-09T23:13:12.775392Z",
     "iopub.status.idle": "2023-06-09T23:13:12.779671Z",
     "shell.execute_reply": "2023-06-09T23:13:12.778850Z"
    },
    "papermill": {
     "duration": 0.015972,
     "end_time": "2023-06-09T23:13:12.781611",
     "exception": false,
     "start_time": "2023-06-09T23:13:12.765639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from IPython.core.display import HTML\n",
    "# HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "176a6c8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T23:13:12.801144Z",
     "iopub.status.busy": "2023-06-09T23:13:12.800494Z",
     "iopub.status.idle": "2023-06-09T23:13:31.791528Z",
     "shell.execute_reply": "2023-06-09T23:13:31.790289Z"
    },
    "papermill": {
     "duration": 19.003793,
     "end_time": "2023-06-09T23:13:31.794348",
     "exception": false,
     "start_time": "2023-06-09T23:13:12.790555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/getdata/* /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22b0c6a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T23:13:31.814216Z",
     "iopub.status.busy": "2023-06-09T23:13:31.813876Z",
     "iopub.status.idle": "2023-06-09T23:13:32.753929Z",
     "shell.execute_reply": "2023-06-09T23:13:32.752756Z"
    },
    "executionInfo": {
     "elapsed": 410,
     "status": "ok",
     "timestamp": 1685803609379,
     "user": {
      "displayName": "Ameck Dosseh",
      "userId": "09603352587859208137"
     },
     "user_tz": -60
    },
    "id": "0iFb5gpzuZXD",
    "outputId": "b0cfb56a-530d-4959-ee8d-0a1580158ed6",
    "papermill": {
     "duration": 0.952767,
     "end_time": "2023-06-09T23:13:32.756514",
     "exception": false,
     "start_time": "2023-06-09T23:13:31.803747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepLabv3FineTuning\t\t    Test.zip\t\t__output__.json\r\n",
      "SampleSubmission.csv\t\t    Train.csv\t\t__results__.html\r\n",
      "SlidinVideos_StarterNotebook.ipynb  Train.zip\t\tcustom.css\r\n",
      "Test\t\t\t\t    __notebook__.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e917397",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T23:13:32.778790Z",
     "iopub.status.busy": "2023-06-09T23:13:32.778431Z",
     "iopub.status.idle": "2023-06-09T23:13:32.782830Z",
     "shell.execute_reply": "2023-06-09T23:13:32.781832Z"
    },
    "executionInfo": {
     "elapsed": 39050,
     "status": "ok",
     "timestamp": 1685804043920,
     "user": {
      "displayName": "Ameck Dosseh",
      "userId": "09603352587859208137"
     },
     "user_tz": -60
    },
    "id": "1jkEZp1euL8c",
    "papermill": {
     "duration": 0.017513,
     "end_time": "2023-06-09T23:13:32.784912",
     "exception": false,
     "start_time": "2023-06-09T23:13:32.767399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Download title masks collection and unzip it to the cloned repository. \n",
    "\n",
    "# !unzip -q Train.zip -d DeepLabv3FineTuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fa71df6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T23:13:32.804885Z",
     "iopub.status.busy": "2023-06-09T23:13:32.804186Z",
     "iopub.status.idle": "2023-06-09T23:13:33.764545Z",
     "shell.execute_reply": "2023-06-09T23:13:33.763400Z"
    },
    "papermill": {
     "duration": 0.973011,
     "end_time": "2023-06-09T23:13:33.767063",
     "exception": false,
     "start_time": "2023-06-09T23:13:32.794052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis.ipynb\tSegmentationDatasetDemo.ipynb  main.py\r\n",
      "CFExp\t\tTests\t\t\t       model.py\r\n",
      "CrackForest\tTrain\t\t\t       requirements.txt\r\n",
      "LICENSE.md\tdatahandler.py\t\t       segdataset.py\r\n",
      "README.md\tenvironment.yml\t\t       trainer.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls DeepLabv3FineTuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd1b50a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T23:13:33.787607Z",
     "iopub.status.busy": "2023-06-09T23:13:33.786730Z",
     "iopub.status.idle": "2023-06-09T23:13:33.791553Z",
     "shell.execute_reply": "2023-06-09T23:13:33.790719Z"
    },
    "papermill": {
     "duration": 0.017019,
     "end_time": "2023-06-09T23:13:33.793514",
     "exception": false,
     "start_time": "2023-06-09T23:13:33.776495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !mkdir DeepLabv3FineTuning/Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "596c4892",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T23:13:33.813129Z",
     "iopub.status.busy": "2023-06-09T23:13:33.812428Z",
     "iopub.status.idle": "2023-06-09T23:13:33.816319Z",
     "shell.execute_reply": "2023-06-09T23:13:33.815431Z"
    },
    "papermill": {
     "duration": 0.015727,
     "end_time": "2023-06-09T23:13:33.818275",
     "exception": false,
     "start_time": "2023-06-09T23:13:33.802548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !mv DeepLabv3FineTuning/Images DeepLabv3FineTuning/Train\n",
    "# !mv DeepLabv3FineTuning/Masks DeepLabv3FineTuning/Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c42c15f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T23:13:33.837869Z",
     "iopub.status.busy": "2023-06-09T23:13:33.837080Z",
     "iopub.status.idle": "2023-06-09T23:13:38.598330Z",
     "shell.execute_reply": "2023-06-09T23:13:38.597073Z"
    },
    "id": "TbZX1CnauSww",
    "outputId": "ab8960ff-2e89-4432-bc07-a9f42e1ba291",
    "papermill": {
     "duration": 4.774884,
     "end_time": "2023-06-09T23:13:38.602021",
     "exception": false,
     "start_time": "2023-06-09T23:13:33.827137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/DeepLabv3FineTuning\n"
     ]
    }
   ],
   "source": [
    "#### Training DeepLab model: our goal is to maximize test_f1_score\n",
    "#### You may want to play with number of epochs, learning rate and loss function to get better results\n",
    "\n",
    "%cd DeepLabv3FineTuning\n",
    "from pathlib import Path\n",
    "\n",
    "#from segmentation_models_pytorch.losses.jaccard  import JaccardLoss\n",
    "#from segmentation_models_pytorch.losses.constants import BINARY_MODE\n",
    "#criterion = JaccardLoss(mode=BINARY_MODE)\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from torch.utils import data\n",
    "\n",
    "import datahandler\n",
    "from model import createDeepLabv3\n",
    "from trainer import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eeba837e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T23:13:38.655170Z",
     "iopub.status.busy": "2023-06-09T23:13:38.654586Z",
     "iopub.status.idle": "2023-06-09T23:13:38.661360Z",
     "shell.execute_reply": "2023-06-09T23:13:38.660432Z"
    },
    "papermill": {
     "duration": 0.02802,
     "end_time": "2023-06-09T23:13:38.663392",
     "exception": false,
     "start_time": "2023-06-09T23:13:38.635372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" FCN Model download and change the head for your prediction\"\"\"\n",
    "from torchvision.models.segmentation.fcn import FCNHead\n",
    "from torchvision.models.segmentation import FCN_ResNet50_Weights\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "def createFCN(outputchannels=1):\n",
    "    \"\"\"FCN class with custom head\n",
    "\n",
    "    Args:\n",
    "        outputchannels (int, optional): The number of output channels\n",
    "        in your dataset masks. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        model: Returns the DeepLabv3 model with the ResNet50 backbone.\n",
    "    \"\"\"\n",
    "    model = models.segmentation.fcn_resnet50(pretrained=True,\n",
    "                                                    progress=True,\n",
    "                                             weights=FCN_ResNet50_Weights.DEFAULT\n",
    "                                             )\n",
    "    model.classifier = FCNHead(2048, outputchannels)\n",
    "    # Set the model in training mode\n",
    "    model.train()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29d7878b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T23:13:38.683655Z",
     "iopub.status.busy": "2023-06-09T23:13:38.683356Z",
     "iopub.status.idle": "2023-06-09T23:13:41.587994Z",
     "shell.execute_reply": "2023-06-09T23:13:41.587099Z"
    },
    "id": "IE1qQYjOwGg3",
    "papermill": {
     "duration": 2.917485,
     "end_time": "2023-06-09T23:13:41.590432",
     "exception": false,
     "start_time": "2023-06-09T23:13:38.672947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/fcn_resnet50_coco-1167a1af.pth\" to /root/.cache/torch/hub/checkpoints/fcn_resnet50_coco-1167a1af.pth\n",
      "100%|██████████| 135M/135M [00:01<00:00, 78.4MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FCN(\n",
       "  (backbone): IntermediateLayerGetter(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): FCNHead(\n",
       "    (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (aux_classifier): FCNHead(\n",
       "    (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the deeplabv3 resnet101 model which is pretrained on a subset\n",
    "# of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.\n",
    "model = createFCN()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40af27d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T23:13:41.617542Z",
     "iopub.status.busy": "2023-06-09T23:13:41.617210Z",
     "iopub.status.idle": "2023-06-09T23:13:41.661610Z",
     "shell.execute_reply": "2023-06-09T23:13:41.659987Z"
    },
    "papermill": {
     "duration": 0.062657,
     "end_time": "2023-06-09T23:13:41.664325",
     "exception": false,
     "start_time": "2023-06-09T23:13:41.601668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from segdataset import SegmentationDataset\n",
    "import multiprocessing\n",
    "pool = multiprocessing.Pool()\n",
    "\n",
    "\n",
    "def get_dataloader_sep_folder(data_dir: str,\n",
    "                              image_folder: str = 'Image',\n",
    "                              mask_folder: str = 'Mask',\n",
    "                              batch_size: int = 4):\n",
    "    \"\"\" Create Train and Test dataloaders from two\n",
    "        separate Train and Test folders.\n",
    "        The directory structure should be as follows.\n",
    "        data_dir\n",
    "        --Train\n",
    "        ------Image\n",
    "        ---------Image1\n",
    "        ---------ImageN\n",
    "        ------Mask\n",
    "        ---------Mask1\n",
    "        ---------MaskN\n",
    "        --Test\n",
    "        ------Image\n",
    "        ---------Image1\n",
    "        ---------ImageM\n",
    "        ------Mask\n",
    "        ---------Mask1\n",
    "        ---------MaskM\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): The data directory or root.\n",
    "        image_folder (str, optional): Image folder name. Defaults to 'Image'.\n",
    "        mask_folder (str, optional): Mask folder name. Defaults to 'Mask'.\n",
    "        batch_size (int, optional): Batch size of the dataloader. Defaults to 4.\n",
    "\n",
    "    Returns:\n",
    "        dataloaders: Returns dataloaders dictionary containing the\n",
    "        Train and Test dataloaders.\n",
    "    \"\"\"\n",
    "    data_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    image_datasets = {\n",
    "        x: SegmentationDataset(root=Path(data_dir) / x,\n",
    "                               transforms=data_transforms,\n",
    "                               image_folder=image_folder,\n",
    "                               mask_folder=mask_folder)\n",
    "        for x in ['Train', 'Test']\n",
    "    }\n",
    "    dataloaders = {\n",
    "        x: DataLoader(image_datasets[x],\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True,\n",
    "                      num_workers=pool._processes)\n",
    "        for x in ['Train', 'Test']\n",
    "    }\n",
    "    return dataloaders\n",
    "\n",
    "\n",
    "def get_dataloader_single_folder(data_dir: str,\n",
    "                                 image_folder: str = 'Images',\n",
    "                                 mask_folder: str = 'Masks',\n",
    "                                 fraction: float = 0.2,\n",
    "                                 batch_size: int = 4):\n",
    "    \"\"\"Create train and test dataloader from a single directory containing\n",
    "    the image and mask folders.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): Data directory path or root\n",
    "        image_folder (str, optional): Image folder name. Defaults to 'Images'.\n",
    "        mask_folder (str, optional): Mask folder name. Defaults to 'Masks'.\n",
    "        fraction (float, optional): Fraction of Test set. Defaults to 0.2.\n",
    "        batch_size (int, optional): Dataloader batch size. Defaults to 4.\n",
    "\n",
    "    Returns:\n",
    "        dataloaders: Returns dataloaders dictionary containing the\n",
    "        Train and Test dataloaders.\n",
    "    \"\"\"\n",
    "    data_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    image_datasets = {\n",
    "        x: SegmentationDataset(data_dir,\n",
    "                               image_folder=image_folder,\n",
    "                               mask_folder=mask_folder,\n",
    "                               seed=100,\n",
    "                               fraction=fraction,\n",
    "                               subset=x,\n",
    "                               transforms=data_transforms)\n",
    "        for x in ['Train', 'Test']\n",
    "    }\n",
    "    dataloaders = {\n",
    "        x: DataLoader(image_datasets[x],\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True,\n",
    "                      num_workers=pool._processes)\n",
    "        for x in ['Train', 'Test']\n",
    "    }\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5aa9f35b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T23:13:41.689695Z",
     "iopub.status.busy": "2023-06-09T23:13:41.688703Z",
     "iopub.status.idle": "2023-06-09T23:13:41.695248Z",
     "shell.execute_reply": "2023-06-09T23:13:41.694483Z"
    },
    "papermill": {
     "duration": 0.021419,
     "end_time": "2023-06-09T23:13:41.697397",
     "exception": false,
     "start_time": "2023-06-09T23:13:41.675978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datahandler.get_dataloader_single_folder = get_dataloader_single_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "224ddabf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T23:13:41.720514Z",
     "iopub.status.busy": "2023-06-09T23:13:41.720223Z",
     "iopub.status.idle": "2023-06-09T23:24:45.925182Z",
     "shell.execute_reply": "2023-06-09T23:24:45.923879Z"
    },
    "id": "36mJmWfrwHiu",
    "papermill": {
     "duration": 664.220382,
     "end_time": "2023-06-09T23:24:45.928857",
     "exception": false,
     "start_time": "2023-06-09T23:13:41.708475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 427/427 [09:24<00:00,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 107/107 [01:35<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0102\n",
      "{'epoch': 1, 'Train_loss': 0.01965971104800701, 'Test_loss': 0.01018694881349802, 'Train_f1_score': 0.47454927953745585, 'Train_auroc': 0.961442479204869, 'Test_f1_score': 0.690224699065678, 'Test_auroc': 0.9749873493047397}\n",
      "Training complete in 11m 4s\n",
      "Lowest Loss: 0.010187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_directory = Path(\"Train\")\n",
    "# Create the experiment directory if not present\n",
    "exp_directory = Path(\"DemoExp\")\n",
    "if not exp_directory.exists():\n",
    "    exp_directory.mkdir()\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "# Specify the evaluation metrics\n",
    "metrics = {'f1_score': f1_score, 'auroc': roc_auc_score}\n",
    "\n",
    "# Create the dataloader\n",
    "dataloaders = datahandler.get_dataloader_single_folder(\n",
    "    data_directory, fraction=0.2, image_folder=\"Images\", \n",
    "    mask_folder=\"Masks\", batch_size=4)\n",
    "\n",
    "\n",
    "\n",
    "# Specify the loss function\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Specify the optimizer with a lower learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "_ = train_model(model, \n",
    "                criterion,\n",
    "                dataloaders,\n",
    "                optimizer,\n",
    "                bpath=exp_directory,\n",
    "                metrics=metrics,\n",
    "                num_epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d20befa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T23:24:46.035057Z",
     "iopub.status.busy": "2023-06-09T23:24:46.034437Z",
     "iopub.status.idle": "2023-06-09T23:24:46.285496Z",
     "shell.execute_reply": "2023-06-09T23:24:46.284531Z"
    },
    "id": "E0_cEwS_wP7P",
    "papermill": {
     "duration": 0.305807,
     "end_time": "2023-06-09T23:24:46.287725",
     "exception": false,
     "start_time": "2023-06-09T23:24:45.981918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the trained model\n",
    "torch.save(model, exp_directory / 'weights.pt')\n",
    "\n",
    "# Terminate\n",
    "exit()\n",
    "%cd ../\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcb1554",
   "metadata": {
    "execution": {},
    "id": "sba8VNgMwQ3f",
    "papermill": {
     "duration": 3.060795,
     "end_time": "2023-06-09T23:24:49.399170",
     "exception": false,
     "start_time": "2023-06-09T23:24:46.338375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 2. Making the submission\n",
    "#### Unpack the testset\n",
    "# !unzip -q Test.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e50b54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T22:58:28.166140Z",
     "iopub.status.busy": "2023-06-09T22:58:28.165193Z",
     "iopub.status.idle": "2023-06-09T22:58:29.154083Z",
     "shell.execute_reply": "2023-06-09T22:58:29.152849Z",
     "shell.execute_reply.started": "2023-06-09T22:58:28.166109Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294ca6f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T22:58:29.156582Z",
     "iopub.status.busy": "2023-06-09T22:58:29.155927Z",
     "iopub.status.idle": "2023-06-09T22:58:29.163299Z",
     "shell.execute_reply": "2023-06-09T22:58:29.162412Z",
     "shell.execute_reply.started": "2023-06-09T22:58:29.156540Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !mkdir Test\n",
    "# !mv Images/ Test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c385365",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T22:58:29.165449Z",
     "iopub.status.busy": "2023-06-09T22:58:29.165097Z",
     "iopub.status.idle": "2023-06-09T22:58:32.265864Z",
     "shell.execute_reply": "2023-06-09T22:58:32.264755Z",
     "shell.execute_reply.started": "2023-06-09T22:58:29.165418Z"
    },
    "id": "xGRe2fN0wVFN",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Load finetuned deeplab model and define helper functions\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import cv2    \n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torchvision import transforms  \n",
    "from PIL import Image\n",
    "\n",
    "deeplab_width = 768\n",
    "deeplab_height = 432\n",
    "deeplab = torch.load('DeepLabv3FineTuning/DemoExp/weights.pt')\n",
    "deeplab.eval()\n",
    "     \n",
    "\n",
    "def boxify(out, boxes):\n",
    "    return [ torch.mean(out[b[0]:b[1], b[2]:b[3]]).item()  for b in boxes ]      \n",
    "\n",
    "def titlesegment(image, boxes):\n",
    "    # Resize the frame to the training input size\n",
    "    inputs = transforms.ToTensor()(Image.fromarray(image, mode=\"RGB\"))\n",
    "    inputs = inputs.reshape(1, *inputs.shape).to('cuda')\n",
    "    \n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = deeplab(inputs)\n",
    "        out = outputs['out'][0][0]\n",
    "        box_scores = boxify(out, boxes)\n",
    "        return out, np.array(box_scores)\n",
    "    \n",
    "def occupation(boxes):\n",
    "    area = lambda b: (b[1]-b[0]) * (b[3]-b[2])\n",
    "    y1, y2 = min([b[0] for b in boxes ]), max([b[1] for b in boxes ])\n",
    "    x1, x2 = min([b[2] for b in boxes ]), max([b[3] for b in boxes ])\n",
    "    return 1.0 * sum([ area(b) for b in boxes ]) / area([y1, y2, x1, x2])\n",
    "\n",
    "# Locates a paragraph of text with the highest probability \n",
    "# to be a slide title \n",
    "def pickonetitle(boxes, scores):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "        \n",
    "    best_idx = np.argmax(scores)\n",
    "    best = boxes[best_idx]\n",
    "\n",
    "    candidates = { i for i, box in enumerate(boxes) \n",
    "        if abs(box['fontsize']-best['fontsize']) <= best['fontsize'] * 0.25 \n",
    "            and scores[best_idx] - scores[i] < 0.6 }\n",
    "    \n",
    "    while occupation([ boxes[i]['bbox'] for i in candidates ]) < 0.75:\n",
    "        combinations = [ candidates - {j} for j in candidates if j != best_idx ]\n",
    "        candidates = max(combinations, \n",
    "            key=lambda comb: occupation([ boxes[j]['bbox'] for j in comb ]))\n",
    "            \n",
    "    title_boxes = [ boxes[i] for i in candidates ]\n",
    "    return title_boxes    \n",
    "\n",
    "#### Now, we're going to use EasyOCR package to \"read\" the titles. Modern OCR solutions may still produce a handful of errors, which is why you're encouraged to apply a language model or alternative OCR model to fix possible misspelings. \n",
    "\n",
    "from shapely.geometry import Polygon, LineString\n",
    "\n",
    "import easyocr\n",
    "reader = easyocr.Reader(['en']) \n",
    "\n",
    "def sameline(a, b):\n",
    "    return ((min(a['bbox'][1], b['bbox'][1]) - max(a['bbox'][0], b['bbox'][0]))\n",
    "            / min(a['height'], b['height'])) >= 0.8\n",
    "            \n",
    "def isbelow(a, b):\n",
    "    return not sameline(a, b) and a['bbox'][0] > b['bbox'][0]  \n",
    "    \n",
    "def isright(a, b):\n",
    "    return sameline(a, b) and a['bbox'][2] > b['bbox'][2]  \n",
    "\n",
    "def sort_boxes(boxes):              \n",
    "    boxes_ = []\n",
    "    for b in boxes:\n",
    "        i = 0\n",
    "        while i < len(boxes_) and (isbelow(b, boxes_[i]) or isright(b, boxes_[i])):\n",
    "            i += 1\n",
    "        boxes_.insert(i, b)\n",
    "    return boxes_\n",
    "\n",
    "def _norm_bbox(bbox):\n",
    "    return  [ int(max(0, min([ p[1] for p in bbox ]))), \n",
    "              int(max([ p[1] for p in bbox ])), \n",
    "              int(max(0, min([ p[0] for p in bbox ]))), \n",
    "              int(max([ p[0] for p in bbox ])) ]\n",
    "\n",
    "def process_ocr(ocr_results):\n",
    "    items = []\n",
    "    for bbox, text, conf in ocr_results:\n",
    "        if text == '' or conf <= 0:\n",
    "            continue  \n",
    "        if not isinstance(bbox, list):\n",
    "            bbox = bbox.tolist()\n",
    "        item = {}\n",
    "        item['width'] = LineString(bbox[0:2]).length\n",
    "        item['height'] = LineString(bbox[1:3]).length\n",
    "        item['area'] = item['width'] * item['height']\n",
    "        item['fontsize'] = 1.0 * item['width'] / len(text)\n",
    "        item['bbox'] = _norm_bbox(bbox)            \n",
    "        item['text'] = text\n",
    "        item['conf'] = float(conf)\n",
    "        items.append(item)\n",
    "    return items     \n",
    "\n",
    "def read_text(img):\n",
    "    return process_ocr(reader.readtext(img))\n",
    "\n",
    "### Data exploration\n",
    "#### First, we will pick some random test slide and will extract any instance of text on it\n",
    "\n",
    "from IPython.display import display, JSON, Image as IImage\n",
    "\n",
    "def draw_boxes(frame, boxes):\n",
    "    for box in boxes:\n",
    "        frame = cv2.rectangle(frame, (box[2], box[0]), (box[3], box[1]), (36,255,12), 2)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49efca9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T22:58:32.268407Z",
     "iopub.status.busy": "2023-06-09T22:58:32.267481Z",
     "iopub.status.idle": "2023-06-09T22:58:33.258490Z",
     "shell.execute_reply": "2023-06-09T22:58:33.257270Z",
     "shell.execute_reply.started": "2023-06-09T22:58:32.268350Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls Test/Images/*33.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fa8f3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T22:58:33.261067Z",
     "iopub.status.busy": "2023-06-09T22:58:33.260301Z",
     "iopub.status.idle": "2023-06-09T22:58:34.324677Z",
     "shell.execute_reply": "2023-06-09T22:58:34.323457Z",
     "shell.execute_reply.started": "2023-06-09T22:58:33.261026Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls Test/Images/*.jpg | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a1777b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T22:58:34.327133Z",
     "iopub.status.busy": "2023-06-09T22:58:34.326768Z",
     "iopub.status.idle": "2023-06-09T22:58:34.333429Z",
     "shell.execute_reply": "2023-06-09T22:58:34.332333Z",
     "shell.execute_reply.started": "2023-06-09T22:58:34.327094Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !ls Test/Images/*.jpg | head -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5635c54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T22:58:34.335431Z",
     "iopub.status.busy": "2023-06-09T22:58:34.335087Z",
     "iopub.status.idle": "2023-06-09T22:58:34.345423Z",
     "shell.execute_reply": "2023-06-09T22:58:34.344432Z",
     "shell.execute_reply.started": "2023-06-09T22:58:34.335379Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "''.join(re.findall(r'\\d+', \"Id_0khgx7z8tk.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252a1f99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T22:58:34.347695Z",
     "iopub.status.busy": "2023-06-09T22:58:34.347285Z",
     "iopub.status.idle": "2023-06-09T22:58:34.832282Z",
     "shell.execute_reply": "2023-06-09T22:58:34.831398Z",
     "shell.execute_reply.started": "2023-06-09T22:58:34.347665Z"
    },
    "id": "Px7j8fmXwirJ",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load some test image and read the text on it\n",
    "slide_ = cv2.imread('Test/Images/Id_76dbm25833.jpg')\n",
    "\n",
    "textboxes_ = read_text(slide_)\n",
    "\n",
    "textdata_ = pd.DataFrame(list(textboxes_))\n",
    "del textdata_['conf']\n",
    "             \n",
    "slide_debug_ = draw_boxes(slide_, [ box['bbox'] for box in textboxes_ ])\n",
    "\n",
    "display(f\"Test slide #33\", \n",
    "    Image.fromarray(slide_debug_).resize((640,360)), textdata_.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722387d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T22:58:34.834286Z",
     "iopub.status.busy": "2023-06-09T22:58:34.833899Z",
     "iopub.status.idle": "2023-06-09T22:58:34.841676Z",
     "shell.execute_reply": "2023-06-09T22:58:34.840671Z",
     "shell.execute_reply.started": "2023-06-09T22:58:34.834250Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "slide_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40314af6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T22:58:34.843968Z",
     "iopub.status.busy": "2023-06-09T22:58:34.843310Z",
     "iopub.status.idle": "2023-06-09T22:58:35.025150Z",
     "shell.execute_reply": "2023-06-09T22:58:35.024083Z",
     "shell.execute_reply.started": "2023-06-09T22:58:34.843933Z"
    },
    "id": "LtmwXdD6wn80",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Now, we will apply finetuned DeepLab model and \"score\" each textbox as to whether it might be a title or not\n",
    "\n",
    "out, scores = titlesegment(slide_, [ box['bbox'] for box in textboxes_ ])\n",
    "out_mask = (np.abs(out.cpu().numpy())*255).astype(np.uint8)\n",
    "\n",
    "textdata_['score'] = scores\n",
    "\n",
    "display(f\"Test slide #33 (segmentation output)\", Image.fromarray(out_mask).resize((640,360)), textdata_.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b2ee7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T22:58:35.027336Z",
     "iopub.status.busy": "2023-06-09T22:58:35.026931Z",
     "iopub.status.idle": "2023-06-09T22:58:35.031932Z",
     "shell.execute_reply": "2023-06-09T22:58:35.030698Z",
     "shell.execute_reply.started": "2023-06-09T22:58:35.027303Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [''.join(re.findall(r'\\d+', x)) for x in os.listdir('Test/Images')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aef3fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T22:58:35.034146Z",
     "iopub.status.busy": "2023-06-09T22:58:35.033777Z"
    },
    "id": "IyHd80jFwrWi",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Iterate this method on all test images\n",
    "from tqdm import tqdm\n",
    "\n",
    "images = sorted(glob.glob('Test/Images/*.jpg'))\n",
    "result = []\n",
    "\n",
    "for path in tqdm(images):\n",
    "    image = cv2.imread(path)\n",
    "    textboxes = read_text(image)\n",
    "\n",
    "    out, scores = titlesegment(image, [ box['bbox'] for box in textboxes ])\n",
    "    titleboxes = pickonetitle(textboxes, scores)\n",
    "    \n",
    "    # Sort text boxes as you would read it in English: from top to bottom\n",
    "    # and from left to right\n",
    "    titleboxes = sort_boxes(titleboxes)\n",
    "    title = ' '.join(box['text'] for box in titleboxes)    \n",
    "    \n",
    "    image_id = path.split(\"/\")[-1] #int(''.join(re.findall(r'\\d+', path.split('.')[0].split('/')[-1])))\n",
    "    result.append([image_id, title])\n",
    "\n",
    "\n",
    "#### Convert the result to a dataframe and save it\n",
    "\n",
    "df = pd.DataFrame.from_records(result, columns=['ID','Title'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3123e7",
   "metadata": {
    "executionInfo": {
     "elapsed": 626,
     "status": "ok",
     "timestamp": 1685803454703,
     "user": {
      "displayName": "Ameck Dosseh",
      "userId": "09603352587859208137"
     },
     "user_tz": -60
    },
    "id": "GedXAwZ0tog7",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('Submission_fcn_resnet50.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c985b9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cee042",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 731.110538,
   "end_time": "2023-06-09T23:24:49.715721",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-09T23:12:38.605183",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
